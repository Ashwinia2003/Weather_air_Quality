{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns after preprocessing: Index(['Body Type', 'Sex', 'Diet', 'Heating Energy Source', 'Transport',\n",
      "       'Vehicle Type'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwini\\AppData\\Local\\Temp\\ipykernel_6800\\2467189131.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)  # Fill categorical missing values with mode\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some columns are still non-numeric. Please review the preprocessing steps.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m non_numeric_cols\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-numeric columns after preprocessing:\u001b[39m\u001b[38;5;124m\"\u001b[39m, non_numeric_cols)\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome columns are still non-numeric. Please review the preprocessing steps.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Scale numerical columns\u001b[39;00m\n\u001b[0;32m     48\u001b[0m numerical_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonthly Grocery Bill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVehicle Monthly Distance Km\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWaste Bag Weekly Count\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     49\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow Long TV PC Daily Hour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow Many New Clothes Monthly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow Long Internet Daily Hour\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Some columns are still non-numeric. Please review the preprocessing steps."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\ashwini\\Downloads\\flask-login-master\\flask-login-master\\Carbon Emission.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)  # Fill numeric missing values with mean\n",
    "for col in data.select_dtypes(include='object').columns:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)  # Fill categorical missing values with mode\n",
    "\n",
    "# Map non-numeric values to numeric equivalents\n",
    "mappings = {\n",
    "    'Social Activity': {'often': 3, 'sometimes': 2, 'rarely': 1, 'never': 0},\n",
    "    'Frequency of Traveling by Air': {'very frequently': 4, 'frequently': 3, 'rarely': 2, 'never': 1},\n",
    "    'Waste Bag Size': {'small': 1, 'medium': 2, 'large': 3, 'extra large': 4},\n",
    "    'How Often Shower': {'daily': 1, 'weekly': 7, 'monthly': 30},\n",
    "    'Energy efficiency': {'No': 0, 'Sometimes': 1, 'Yes': 2}  # Added mapping for 'Energy efficiency'\n",
    "}\n",
    "\n",
    "# Apply mappings\n",
    "for column, mapping in mappings.items():\n",
    "    if column in data.columns:\n",
    "        data[column] = data[column].map(mapping)\n",
    "\n",
    "# Drop 'Recycling' and 'Cooking_With' columns\n",
    "data = data.drop(['Recycling', 'Cooking_With'], axis=1)\n",
    "\n",
    "# Encode remaining categorical columns using LabelEncoder\n",
    "categorical_columns = ['Body Type', 'Sex', 'Diet', 'Transport', 'Vehicle Type', 'Heating Energy Source']\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))  # Convert to string before encoding\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Verify all columns are numeric\n",
    "non_numeric_cols = data.dtypes[data.dtypes.apply(lambda x: x not in ['int64', 'float64'])].index\n",
    "if non_numeric_cols.any():\n",
    "    print(\"Non-numeric columns after preprocessing:\", non_numeric_cols)\n",
    "    raise ValueError(\"Some columns are still non-numeric. Please review the preprocessing steps.\")\n",
    "\n",
    "# Scale numerical columns\n",
    "numerical_columns = ['Monthly Grocery Bill', 'Vehicle Monthly Distance Km', 'Waste Bag Weekly Count', \n",
    "                     'How Long TV PC Daily Hour', 'How Many New Clothes Monthly', 'How Long Internet Daily Hour']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data.drop('CarbonEmission', axis=1)\n",
    "y = data['CarbonEmission']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"carbon_model.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the trained model and preprocessing objects\n",
    "joblib.dump(model, \"carbon_footprint_model.pkl\")\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"Model and preprocessors saved successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "\n",
    "# Load the trained model, scaler, and label encoders\n",
    "model = joblib.load('carbon_footprint_model.pkl')\n",
    "label_encoders = joblib.load('label_encoders.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Sample input data without 'Recycling' and 'Cooking_With' columns\n",
    "input_data = {\n",
    "    'Body Type': ['overweight'],\n",
    "    'Sex': ['female'],\n",
    "    'Diet': ['pescatarian'],\n",
    "    'How Often Shower': ['daily'],\n",
    "    'Heating Energy Source': ['coal'],\n",
    "    'Transport': ['public'],\n",
    "    'Vehicle Type': ['petrol'],\n",
    "    'Social Activity': ['often'],\n",
    "    'Monthly Grocery Bill': [230],\n",
    "    'Frequency of Traveling by Air': ['frequently'],\n",
    "    'Vehicle Monthly Distance Km': [210],\n",
    "    'Waste Bag Size': ['large'],\n",
    "    'Waste Bag Weekly Count': [4],\n",
    "    'How Long TV PC Daily Hour': [7],\n",
    "    'How Many New Clothes Monthly': [26],\n",
    "    'How Long Internet Daily Hour': [1],\n",
    "    'Energy efficiency': ['No']\n",
    "}\n",
    "\n",
    "# Convert the input data to a DataFrame\n",
    "input_df = pd.DataFrame(input_data)\n",
    "\n",
    "# Apply the same mappings for non-numeric columns\n",
    "for column, mapping in mappings.items():\n",
    "    if column in input_df.columns:\n",
    "        input_df[column] = input_df[column].map(mapping)\n",
    "\n",
    "# Encode categorical columns using the saved label encoders\n",
    "for col, le in label_encoders.items():\n",
    "    input_df[col] = le.transform(input_df[col].astype(str))\n",
    "\n",
    "# Scale numerical columns using the saved scaler\n",
    "numerical_columns = ['Monthly Grocery Bill', 'Vehicle Monthly Distance Km', 'Waste Bag Weekly Count',\n",
    "                     'How Long TV PC Daily Hour', 'How Many New Clothes Monthly', 'How Long Internet Daily Hour']\n",
    "input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "# Predict the carbon emission\n",
    "predicted_emission = model.predict(input_df)\n",
    "\n",
    "# Output the predicted carbon emission\n",
    "print(f\"Predicted Carbon Emission: {predicted_emission[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Carbon Emission: 2361.67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model, scaler, and label encoders\n",
    "model = joblib.load('carbon_footprint_model.pkl')\n",
    "label_encoders = joblib.load('label_encoders.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Input data (use the same values as provided)\n",
    "input_data = {\n",
    "    'Body Type': ['overweight'],  # Input your value\n",
    "    'Sex': ['female'],            # Input your value\n",
    "    'Diet': ['pescatarian'],      # Input your value\n",
    "    'How Often Shower': ['daily'],  # Input your value\n",
    "    'Heating Energy Source': ['coal'],  # Input your value\n",
    "    'Transport': ['public'],         # Input your value\n",
    "    'Vehicle Type': ['petrol'],          # Input your value or None if not applicable\n",
    "    'Social Activity': ['often'],    # Input your value\n",
    "    'Monthly Grocery Bill': [230],   # Input your value\n",
    "    'Frequency of Traveling by Air': ['frequently'],  # Input your value\n",
    "    'Vehicle Monthly Distance Km': [210],  # Input your value\n",
    "    'Waste Bag Size': ['large'],     # Input your value\n",
    "    'Waste Bag Weekly Count': [4],   # Input your value\n",
    "    'How Long TV PC Daily Hour': [7],  # Input your value\n",
    "    'How Many New Clothes Monthly': [26],  # Input your value\n",
    "    'How Long Internet Daily Hour': [1],  # Input your value\n",
    "    'Energy efficiency': ['No'],     # Input your value\n",
    "    'Recycling': [['Metal']],         # Input your value\n",
    "    'Cooking_With': [['Stove', 'Oven']]  # Input your value\n",
    "}\n",
    "\n",
    "# Convert the input data to a DataFrame\n",
    "input_df = pd.DataFrame(input_data)\n",
    "\n",
    "# Apply the same mappings for non-numeric columns as in the training phase\n",
    "mappings = {\n",
    "    'Social Activity': {'often': 3, 'sometimes': 2, 'rarely': 1, 'never': 0},\n",
    "    'Frequency of Traveling by Air': {'very frequently': 4, 'frequently': 3, 'rarely': 2, 'never': 1},\n",
    "    'Waste Bag Size': {'small': 1, 'medium': 2, 'large': 3, 'extra large': 4},\n",
    "    'How Often Shower': {'daily': 1, 'weekly': 7, 'monthly': 30},\n",
    "    'Energy efficiency': {'No': 0, 'Sometimes': 1, 'Yes': 2}\n",
    "}\n",
    "\n",
    "# Apply mappings\n",
    "for column, mapping in mappings.items():\n",
    "    if column in input_df.columns:\n",
    "        input_df[column] = input_df[column].map(mapping)\n",
    "\n",
    "# Encode categorical columns using the saved label encoders\n",
    "for col, le in label_encoders.items():\n",
    "    input_df[col] = le.transform(input_df[col].astype(str))\n",
    "\n",
    "# Scale numerical columns using the saved scaler\n",
    "numerical_columns = ['Monthly Grocery Bill', 'Vehicle Monthly Distance Km', 'Waste Bag Weekly Count',\n",
    "                     'How Long TV PC Daily Hour', 'How Many New Clothes Monthly', 'How Long Internet Daily Hour']\n",
    "input_df[numerical_columns] = scaler.transform(input_df[numerical_columns])\n",
    "\n",
    "# Predict the carbon emission\n",
    "predicted_emission = model.predict(input_df)\n",
    "\n",
    "# Output the predicted carbon emission\n",
    "print(f\"Predicted Carbon Emission: {predicted_emission[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Missing values handled.\n",
      "Non-numeric columns mapped to numeric equivalents.\n",
      "Columns ['Recycling', 'Cooking_With'] dropped.\n",
      "Categorical columns encoded.\n",
      "Numerical columns scaled.\n",
      "Dataset split into training and testing sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwini\\AppData\\Local\\Temp\\ipykernel_9416\\2713010501.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)  # Fill categorical missing values with mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "RMSE: 302.6941687057252\n",
      "Model and preprocessors saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashwini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\ashwini\\Downloads\\flask-login-master\\flask-login-master\\Carbon Emission.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)  # Fill numeric missing values with mean\n",
    "for col in data.select_dtypes(include='object').columns:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)  # Fill categorical missing values with mode\n",
    "print(\"Missing values handled.\")\n",
    "\n",
    "# Map non-numeric values to numeric equivalents\n",
    "mappings = {\n",
    "    'Social Activity': {'often': 3, 'sometimes': 2, 'rarely': 1, 'never': 0},\n",
    "    'Frequency of Traveling by Air': {'very frequently': 4, 'frequently': 3, 'rarely': 2, 'never': 1},\n",
    "    'Waste Bag Size': {'small': 1, 'medium': 2, 'large': 3, 'extra large': 4},\n",
    "    'How Often Shower': {'daily': 1, 'weekly': 7, 'monthly': 30},\n",
    "    'Energy efficiency': {'No': 0, 'Sometimes': 1, 'Yes': 2}\n",
    "}\n",
    "for column, mapping in mappings.items():\n",
    "    if column in data.columns:\n",
    "        data[column] = data[column].map(mapping)\n",
    "print(\"Non-numeric columns mapped to numeric equivalents.\")\n",
    "\n",
    "# Drop unused columns\n",
    "columns_to_drop = ['Recycling', 'Cooking_With']\n",
    "data.drop(columns=columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "print(f\"Columns {columns_to_drop} dropped.\")\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_columns = ['Body Type', 'Sex', 'Diet', 'Transport', 'Vehicle Type', 'Heating Energy Source']\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))  # Convert to string before encoding\n",
    "    label_encoders[col] = le\n",
    "print(\"Categorical columns encoded.\")\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "non_numeric_cols = data.dtypes[data.dtypes.apply(lambda x: x not in ['int64', 'float64'])].index\n",
    "if non_numeric_cols.any():\n",
    "    print(\"Non-numeric columns after preprocessing:\", non_numeric_cols)\n",
    "    raise ValueError(\"Some columns are still non-numeric. Please review the preprocessing steps.\")\n",
    "\n",
    "# Scale numerical columns\n",
    "numerical_columns = ['Monthly Grocery Bill', 'Vehicle Monthly Distance Km', 'Waste Bag Weekly Count',\n",
    "                     'How Long TV PC Daily Hour', 'How Many New Clothes Monthly', 'How Long Internet Daily Hour']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "print(\"Numerical columns scaled.\")\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data.drop('CarbonEmission', axis=1)\n",
    "y = data['CarbonEmission']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Dataset split into training and testing sets.\")\n",
    "\n",
    "# Train a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Save the trained model and preprocessing objects\n",
    "model_dir = \"model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "joblib.dump(model, os.path.join(model_dir, \"carbon_footprint_model.pkl\"))\n",
    "joblib.dump(label_encoders, os.path.join(model_dir, \"label_encoders.pkl\"))\n",
    "joblib.dump(scaler, os.path.join(model_dir, \"scaler.pkl\"))\n",
    "print(\"Model and preprocessors saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
